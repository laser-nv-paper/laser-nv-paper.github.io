
<!doctype html>
<html lang="en">
  <head>
    <!-- Remove to make it visible in search engines -->
    <!-- <meta name="robots" content="noindex"> -->

    <meta charset="utf-8"/>
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="google-site-verification" content="w_OUXCNMpd9b_KL9wO2jpRYvW5dixRKLSILblWUkCiE" />
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
          rel="stylesheet"
	  integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3"
	  crossorigin="anonymous">

    <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/styles/default.min.css">
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>

    <title>Laser: Latent Set Representations for 3D Generative Modeling</title>
    <style>
      .paper-title {
        margin-top: 2em;
        margin-bottom: 2em;
      }
      .long-name {
        font-size: 1.5em;
      }
      .authors-list .name {
        font-size: 0.7em;
        /*font-weight: bold;*/
      }
      .authors-list .affiliation {
        font-size: 1.0em;
      }
      .paper-link a {
        font-size: 1.5em;
      }
      .short-videos video {
        padding: 1em;
      }
      .content-block {
        padding-left: 2em;
        padding-right: 2em;
        padding-bottom: 2em;
      }
      .overview-video {
        background-color: rgb(240,240,240);
      }
      .overview-video .video-col {
        margin-left: 2em;
        margin-right: 2em;
      }
      .video-row {
        margin-top: 1em;
        margin-bottom: 1em;
      }
      .geometric-consistency {
        background-color: rgb(240,240,240);
      }
      .code {
        background-color: rgb(240,240,240);
      }
      .dataset {
/*         background-color: rgb(240,240,240); */
      }
      .citation {
/*         background-color: rgb(240,240,240); */
      }
      .citation .description {
        font-family: "Courier",monospace;
        white-space: pre-wrap;
        text-align: left;
        font-size: 0.7em;
      }
      .additional-links {
        background-color: #f4f4f4;
      }
      .textcommumn {
        text-align: center;
      }
      @media (min-width: 1000px) {
	      .container {
		      max-width: 900px;
	      }
      }
      .teaser {
	      width: 100%;
	      max-width: 620px;
      }

      .my_container {
        display: flex;
        flex-flow: row nowrap;
        justify-content: center;
        /* align-items: center; */
        /* align-content: center; */
        /* gap: 0px; */
        /* height: 256px; */
        /* width: 1000px; */
        padding: 0;
        margin: 0;
      }

      .my_element {
        margin: auto;
        /* display: box; */
        padding: 5px 25px 5px;
        height: 256px;
        line-height: 256px;
        font-weight: bold;
        font-size: 3em;
        text-align: center;
        list-style-type: none;
      }

      .my_added_padding {
        padding-top: 25px
      }
    </style>
  </head>

  <body>
    <div class="container">
      <div class="paper-title">
        <!-- title -->
        <div class="row">
          <div class="col">
		  <h1 class="name text-center">Laser: Latent Set Representations for 3D Generative Modeling</h1>
          </div>
        </div>
        <div class="row">
          <div class="col">
          </div>
        </div>

      <!-- Authors -->
      <div class="authors-list">
        <br>
        <div class="row gx-1">
          <div class="col">
            <p class="name text-center">
            <a href="https://scholar.google.com/citations?user=CY0-T_MAAAAJ&hl=en"
	       target="_blank" >Pol*</br>Moreno</a> <a href="mailto:polc@deepmind.com">ðŸ“§</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://akosiorek.github.io/"
	       target="_blank" >Adam* R.</br>Kosiorek</a> <a href="mailto:adamrk@deepmind.com">ðŸ“§</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://scholar.google.co.uk/citations?user=QFseZ2gAAAAJ&hl=en"
		    target="_blank" >Heiko</br>Strathmann</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://scholar.google.com/citations?user=1JQDH_AAAAAJ&hl=en&oi=ao"
		    target="_blank" >Daniel</br>Zoran</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a
            <a href="https://scholar.google.com/citations?user=Ysx_wZgAAAAJ&hl=en"
		    target="_blank" >Rosalia G.</br>Schneider</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a>BjÃ¶rn</br>Winckler</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://scholar.google.com/citations?user=jM6Y0yAAAAAJ&hl=en&oi=ao"
		    target="_blank" >Larisa</br>Markeeva</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://scholar.google.com/citations?user=LZxqcX4AAAAJ&hl=en&oi=ao"
		    target="_blank" >ThÃ©ophane</br>Weber</a>
            </p>
          </div>
          <div class="col">
            <p class="name text-center">
            <a href="https://danilorezende.com/"
	       target="_blank" >Danilo J.</br>Rezende</a>
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
		  <p class="text-center">
      <br>
	    <img src="data/deepmind_logo.svg" alt="Deepmind" width="150em"/>
		  </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
		  <!-- <p class="text-center">
	            CVPR 2022
		  </p> -->
          </div>
        </div>
      </div>
    </div>

      <!-- Links -->
      <div class="paper-link">
        <div class="row">
          <div class="col">
            <p class="text-center">
	      <a href="https://arxiv.org/abs/2301.05747">[Paper]</a>
		    <!-- &nbsp;&nbsp;&nbsp;&nbsp;
	      <a href="#code">[Code]</a>
		    &nbsp;&nbsp;&nbsp;&nbsp;
	      <a href="#dataset">[Dataset]</a> -->
            </p>
          </div>
        </div>
      </div>

      <!-- Abstract -->
      <div class="abstract content-block">
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Abstract</h3>
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
      <p class="text">
        NeRF provides unparalleled fidelity of novel view synthesis&#8212;rendering a 3D scene from an arbitrary viewpoint. NeRF requires training on a large number of views that fully cover a scene, which limits its applicability.
        While these issues can be addressed by learning a prior over scenes in various forms, previous approaches have been either applied to overly simple scenes or struggling to render unobserved parts.
        We introduce Laser-NV&#8212;a generative model which achieves high modelling capacity, and which is based on a set-valued latent representation modelled by normalizing flows.
        Similarly to previous amortized approaches, Laser-NV learns structure from multiple scenes and is capable of fast, feed-forward inference from few views.
        To encourage higher rendering fidelity and consistency with observed views, Laser-NV further incorporates a geometry-informed attention mechanism over the observed views.
        Laser-NV further produces diverse and plausible completions of occluded parts of a scene while remaining consistent with observations.
        Laser-NV shows state-of-the-art novel-view synthesis quality when evaluated on ShapeNet and on a novel simulated City dataset, which features high uncertainty in the unobserved regions of the scene.</p>
      <p class="text">
      </p>
      <p class="text">
      </p>
          </div>
        </div>
      </div>

      <!-- Teaser -->
      <div class="content-block">
        <div class="row">
          <div class="col text-center" style="display: flex; align-items: center; justify-content: center">
            <div style="position: relative; max-width: 620px; width: 100%;">
              <img src="data/teaser.svg" alt="Model Overview" class="teaser"/>
              <div style="overflow:hidden; width:64px; position: absolute; top:17%; right:4%;">
                <video loop="True" autoplay muted
                 style="margin-right:-25%; max-width:256px;">
                    <source src="data/city/city_variance_vid.webm" type="video/webm">
                </video>
              </div>
            </div>
          </div>
		  <p class="text">
NeRF-VAE with Latent Set Representation (Laser-NV) is a generative model over
3D scenes. It can <strong>sample new scenes from the prior</strong>, or <strong>complete existing scenes</strong>
based on sparse observations.
      </p>
      <p>
The <strong>latent set representation</strong> of a 3D scene is modelled by a permutation-invariant
normalizing flow based on Transformers. Laser-NV's decoder is based on NeRF, but
uses <strong>cross-attention</strong> to <strong>attend</strong> to the latent set as well as <strong>local features reprojected
from available observations</strong>.
      </p>
        </div>
      </div>

      <!-- City inpainting overview -->
      <div class="content-block">
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Scene Completion</h3>
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col text-center">
            <div style="overflow:hidden; display:block; margin:0; padding:0;">
              <video loop="True" autoplay muted width="650px"
              style="margin-bottom: -70px; margin-top: -70px" >
                  <source src="data/city/city_overview.mp4" type="video/mp4" >
              </video>
            </div>
          </div>
      <p>
Laser-NV can complete a scene from partial observations. Rendering a novel
viewpoint (red) may require inpainting unobsered parts of the scene (gray) based
on the latent representation. Inpainting needs to be consistent with
observed views. This is accomplished by reprojecting local features from the
observed views (green arrows).
      </p>
        </div>
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Diverse Outputs</h3>
            </p>
          </div>
        </div>
        <!-- nmr chairs laser-nv vs deterministic baseline -->
        <div class="row">
          <div class="col text-center">
            <img src="data/nmr/chairs_varied_completions.png" width="800px">
          </div>
        </div>
        <p><br>
As a stochastic generative model, Laser-NV can sample diverse solutions compatible
with the observed context. In the middle we see three ShapeNet chairs, each with a different
backrest, but all compatible with the context. Compare that to a single solution of a
deterministic baseline on the right.
        </p>
        <!-- same obs -> multiple diverse city fly-throughs -->
        <div class="row">
          <div class="col">
          <ul class="my_container">
            <li class="my_element">
              <div style="width:128px">
                <img src="data/city/city_variance_context.png" width="128px">
              </div>
            </li>
            <li class="my_element">
              &rarr;
            </li>
            <li class="my_element">
              <video width="512px" loop="True" autoplay muted>
                  <source src="data/city/city_variance_vid.webm" type="video/webm">
              </video>
            </li>
          </ul>
          </div>
        </div>
        <p><br>
Similarly, Laser-NV can inpaint missing parts of the
scene in many different ways. Here we show 4 prior samples (right) conditioned
on the same two observations (left). The observed parts of the scene are consistent
with the observations, but the unobserved parts are different. To make these
visualisations we trained the model on a dataset containing birds-eye views of
the City.
        </p>
      </div>




      <!-- Supplementary videos -->
      <div class="content-block additional-links">
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Conditional Generation Examples</h3>
            </p>
          </div>
        </div>
        <div class="row textcommumn">
          <div class="col">
            <a href="data/city.html">
              <video width="256px" autoplay loop="True" muted>
                <source src="data/city/city_360_vid_0.mp4" type="video/mp4">
              </video>
              <p>
                City
              </p>
            </a>
          </div>
          <div class="col">
            <a href="data/msn.html">
              <video width="256px" autoplay loop="True" muted>
                <source src="data/msn/msn_vid_5.mp4" type="video/mp4">
              </video>
              <p>
                MultiShapeNet (MSN)
              </p>
            </a>
          </div>
          <div class="col">
            <a href="data/nmr.html">
              <video width="256px" autoplay loop="True" muted>
                <source src="data/nmr/shapenet_vid_2.mp4" type="video/mp4">
              </video>
              <p>
                ShapeNet (NMR)
              </p>
            </a>
          </div>
        </div>
      </div>

      <!-- spacing between examples and code blocks -->
      <!-- <div class="content-block"></div> -->

      <!-- Code -->
      <!-- <div class="content-block code", id="code">
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Code</h3>
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
            <p class="text">
              To be released.
            </p>
          </div>
        </div>
      </div> -->

      <!-- Dataset -->
      <!-- <div class="content-block dataset", id="dataset">
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Dataset</h3>
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
            <p class="text">
            To be released.
            </p>
          </div>
        </div>
      </div> -->

  <!-- Citation -->
      <div class="content-block citation">
        <div class="row">
          <div class="col">
            <p class="title">
              <h3>Citation</h3>
            </p>
          </div>
        </div>
        <div class="row">
          <div class="col">
            <p class="description">
@article{lasernv2022,
  title={{Laser: Latent Set Representations for 3D Generative Modeling}},
  author={Pol Moreno and Adam R. Kosiorek and Heiko Strathmann and Daniel Zoran and Rosalia G. Schneider and BjÃ¶rn Winckler and Larisa Markeeva and Th{\'e}ophane Weber and Danilo J. Rezende},
  journal={{arXiv}},
  year={2022},
  url={https://laser-nv-paper.github.io/},
}
            </p>
          </div>
        </div>
      </div>

      <!-- Citation -->
          <div class="content-block citation">
            <div class="row">
              <div class="col">
                <h4>Acknowledgements</h4>
                <p>
    This website is based on <a href="https://srt-paper.github.io">https://srt-paper.github.io<a/>. We thank the authors
    for the template and for the model fig inspiration.
                </p>
              </div>
            </div>
          </div>

    </div>

<!-- Bootstrap bits -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
	    integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
    	    crossorigin="anonymous"></script>
  </body>
</html>
